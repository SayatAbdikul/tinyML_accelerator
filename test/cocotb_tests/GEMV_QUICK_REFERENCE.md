# GEMV Testbench - Quick Reference

## What Was Created

A production-ready cocotb testbench for validating the `top_gemv` RTL module against a Python golden model.

## Quick Start (Copy-Paste Ready)

```bash
cd test/cocotb_tests
source .venv/bin/activate
make TEST_TARGET=top_gemv run_test
```

**Expected Output:**
```
** TESTS=3 PASS=3 FAIL=0 SKIP=0
** test_top_gemv.test_top_gemv_small                     PASS
** test_top_gemv.test_top_gemv_medium                    PASS  
** test_top_gemv.test_top_gemv_with_quantization_check   PASS
```

## Test Files Created

| File | Purpose | Type |
|------|---------|------|
| `test_top_gemv.py` | Cocotb testbench with 3 test cases | Python/cocotb |
| `make_venv.sh` | Auto-activate venv wrapper | Bash |
| `run_gemv_tests.sh` | Quick-start runner | Bash |
| `run_gemv_test.py` | Python test runner | Python |
| `GEMV_TESTBENCH_GUIDE.md` | Detailed developer guide | Documentation |
| `GEMV_TESTBENCH_SUMMARY.md` | Implementation summary | Documentation |
| Updated `README.md` | Installation and usage | Documentation |
| Updated `Makefile` | Multi-target support | Build system |

## The Three Tests

### 1. test_top_gemv_small
- **Matrix**: 4 rows Ã— 8 cols
- **Purpose**: Quick validation (~0.1s)
- **Status**: âœ… PASSING

### 2. test_top_gemv_medium
- **Matrix**: 16 rows Ã— 32 cols
- **Purpose**: Scalability check (~0.1s)
- **Status**: âœ… PASSING

### 3. test_top_gemv_with_quantization_check
- **Matrix**: 2 rows Ã— 4 cols (fixed values)
- **Purpose**: Detailed quantization verification (~0.1s)
- **Status**: âœ… PASSING

## How It Works

```
Test Flow:
  1. Generate test data (weights, inputs, bias) OR use fixed values
  2. Run golden model GEMV: y = W @ x + bias
  3. Configure RTL module (dimensions, vectors)
  4. Stream weight matrix to RTL (row-by-row)
  5. Wait for RTL computation to complete
  6. Compare RTL output against golden model (tolerance: Â±2 LSBs)
  7. Report PASS/FAIL with detailed logging
```

## Key Features

âœ… **Comprehensive** - 3 test cases, 1000+ lines of well-documented code
âœ… **Accurate** - Golden model uses same quantization as RTL
âœ… **Fast** - All tests complete in <0.5 seconds
âœ… **Reproducible** - Fixed seeds ensure deterministic results
âœ… **Easy to extend** - Simple patterns for adding custom tests
âœ… **Well documented** - Guides, examples, and troubleshooting

## Alternative Run Methods

**If venv already activated:**
```bash
make TEST_TARGET=top_gemv run_test
```

**Using wrapper script (no venv activation needed):**
```bash
./make_venv.sh TEST_TARGET=top_gemv run_test
```

**Using Python convenience script:**
```bash
python3 run_test.py --gemv
```

**Using Bash quick-start:**
```bash
./run_gemv_tests.sh
```

## Troubleshooting

| Issue | Solution |
|-------|----------|
| "Can not find root handle" | Run `source .venv/bin/activate` first |
| "w_ready not asserted" | Check top_gemv.sv state machine |
| "Timeout on done" | Increase timeout in test or check RTL logic |
| "Output mismatch > 2" | Verify quantize_int32_to_int8 implementation |

## Key Implementation Details

### Golden Model (`GoldenGEMV` class)
```python
class GoldenGEMV:
    @staticmethod
    def gemv(weights, x, bias, rows, cols):
        """Compute y = W @ x + bias with quantization"""
        # Compute in int32 to prevent overflow
        y_int32 = compute_gemv_int32(weights, x, bias)
        
        # Calculate dynamic scale
        max_abs = max(abs(y_int32))
        scale = max_abs / 127.0
        
        # Quantize to int8
        y_quantized = quantize_int32_to_int8(y_int32, scale, 0)
        return y_int32, y_quantized, scale
```

### RTL Interface
- **Inputs**: clk, rst, start, rows, cols, x[], bias[], w_tile_row_in[], w_valid
- **Outputs**: w_ready, done, y[]
- **Handshake**: w_ready/w_valid for weight streaming
- **Tile size**: 32 (TILE_SIZE parameter)

## File Locations

```
tinyML_accelerator/
â””â”€â”€ test/cocotb_tests/
    â”œâ”€â”€ test_top_gemv.py                    â† Main testbench
    â”œâ”€â”€ make_venv.sh                        â† Wrapper script
    â”œâ”€â”€ run_gemv_tests.sh                   â† Quick-start bash
    â”œâ”€â”€ run_gemv_test.py                    â† Python runner
    â”œâ”€â”€ GEMV_TESTBENCH_GUIDE.md            â† Detailed guide
    â”œâ”€â”€ GEMV_TESTBENCH_SUMMARY.md          â† Implementation summary
    â”œâ”€â”€ README.md                           â† Updated with GEMV instructions
    â””â”€â”€ Makefile                            â† Updated with TEST_TARGET support
```

## Golden Model Integration

The testbench uses the existing `helper_functions.py` from the compiler directory:
- Imports: `from helper_functions import quantize_int32_to_int8`
- This ensures exact matching between RTL and golden model quantization
- Python path automatically configured

## Performance Metrics

```
Test                                      Sim Time    Real Time   Speed
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
test_top_gemv_small (4Ã—8)                10.97 Âµs    0.09 s      ~130k ns/s
test_top_gemv_medium (16Ã—32)             11.69 Âµs    0.07 s      ~180k ns/s
test_top_gemv_with_quantization_check    10.85 Âµs    0.06 s      ~190k ns/s
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total                                    33.51 Âµs    0.46 s      ~70k ns/s
```

## For Developers

### Adding a Custom Test
```python
@cocotb.test()
async def test_top_gemv_custom(dut):
    """My custom test."""
    # Set parameters
    rows, cols = 8, 16
    
    # Generate test data
    weights = np.random.randint(-128, 127, rows*cols, dtype=np.int8)
    x_input = np.random.randint(-128, 127, cols, dtype=np.int8)
    bias = np.random.randint(-128, 127, rows, dtype=np.int8)
    
    # Run golden model
    golden = GoldenGEMV()
    _, y_golden, _ = golden.gemv(weights, x_input, bias, rows, cols)
    
    # Drive RTL (see existing tests for pattern)
    # ... setup clock, reset, load inputs, stream weights, wait for done ...
    
    # Compare
    assert max_error <= 2
```

### Inspecting Waveforms
```bash
# After test completes:
gtkwave sim_build/dump.vcd &

# In GTKWave, search for "top_gemv" in hierarchy
# Watch: w_ready, w_valid, done, y[]
```

## Next Steps

1. âœ… **Done** - Testbench created and all tests passing
2. âœ… **Done** - Documentation complete
3. ğŸ“ **Current** - You are here (reading this summary)
4. **Next** - Integrate into CI/CD pipeline if desired
5. **Next** - Add more test cases for edge cases if needed

## Questions?

See the detailed documentation:
- **Overview & Usage**: `README.md`
- **Detailed Guide**: `GEMV_TESTBENCH_GUIDE.md`
- **Implementation**: `GEMV_TESTBENCH_SUMMARY.md`
- **Test Code**: `test_top_gemv.py`

---

**Status**: âœ… Production Ready - All tests passing, fully documented, easy to use
